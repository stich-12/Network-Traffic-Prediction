{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Traffic Classification and Intrusion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the book <em>Machine Learning & Security</em> by Clarence Chio & David Freeman, I use the NSL-KDD dataset (https://www.unb.ca/cic/datasets/nsl.html) to classify network attacks. I begin with a similar approach as Chio and Freeman in classifying specific network attacks using supervised learning. I revise this approach, developing an intrusion detection algorithm, using a combination of supervised and unsupervised binary classification models and strategies. I then evaluate the model and compare the 2 approaches to intrusion detection, weighing the pros and cons of each. Finally, I create an interactive dashboard prototype for a security team, incorporating explainability models, charts, rough measures of risk, and basic examples of remediation recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Background\n",
    "- Data Source: https://www.unb.ca/cic/datasets/nsl.html\n",
    "- Feature Descriptions: https://kdd.ics.uci.edu/databases/kddcup99/task.html, https://www.aldapa.eus/res/gureKddcup/README.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Categories\n",
    "- dos: denial of service\n",
    "- r2l: unauthorized access from remote servers\n",
    "- u2r: privilege escalation attempts\n",
    "- probe: brute force probing attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-deeper-dive-into-the-nsl-kdd-data-set-15c753364657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Setup\n",
    "2. Data Exploration and Feature Selection\n",
    "3. Resampling\n",
    "4. Supervised Modeling\n",
    "   - Selecting a classifier\n",
    "       - Multi-class Classification\n",
    "       - Binary Classiciation and Feature Engineering\n",
    "   \n",
    "5. Threshold Selection (Optimizing precision and recall)  \n",
    "6. Unsupervised Modeling - Clustering\n",
    "7. Combine Supervised and Unsupervised Models\n",
    "8. Evaluation\n",
    "9. Explainability\n",
    "10. Dashboard\n",
    "11. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "from scipy.stats import uniform\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from random import randint\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'nsl-kdd/KDDTrain+.txt'\n",
    "test_file = 'nsl-kdd/KDDTest+.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = defaultdict(list)\n",
    "category['benign'].append('normal')\n",
    "\n",
    "with open('nsl-kdd/training_attack_types.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        attack, cat = line.strip().split(' ')\n",
    "        category[cat].append(attack)\n",
    "\n",
    "attack_mapping = dict((v,k) for k in category for v in category[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack_type', 'success_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_master = pd.read_csv(train_file, names=header_names)\n",
    "df_train_master['attack_category'] = df_train_master['attack_type'] \\\n",
    "                                .map(lambda x: attack_mapping[x])\n",
    "df_train_master.drop(['success_pred'], axis=1, inplace=True)\n",
    "    \n",
    "df_test = pd.read_csv(test_file, names=header_names)\n",
    "df_test['attack_category'] = df_test['attack_type'] \\\n",
    "                                .map(lambda x: attack_mapping[x])\n",
    "df_test.drop(['success_pred'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>attack_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "   attack_type  attack_category  \n",
       "0       normal           benign  \n",
       "1       normal           benign  \n",
       "2      neptune              dos  \n",
       "3       normal           benign  \n",
       "4       normal           benign  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign    67343\n",
       "dos       45927\n",
       "probe     11656\n",
       "r2l         995\n",
       "u2r          52\n",
       "Name: attack_category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['attack_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>182.148945</td>\n",
       "      <td>115.653005</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.148379</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.278485</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>0.120240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>99.206213</td>\n",
       "      <td>110.702741</td>\n",
       "      <td>0.448949</td>\n",
       "      <td>0.188922</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.444784</td>\n",
       "      <td>0.445669</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.319459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...  dst_host_count  \\\n",
       "count  125973.000000    125973.000000  ...   125973.000000   \n",
       "mean        0.395736         0.279250  ...      182.148945   \n",
       "std         0.489010        23.942042  ...       99.206213   \n",
       "min         0.000000         0.000000  ...        0.000000   \n",
       "25%         0.000000         0.000000  ...       82.000000   \n",
       "50%         0.000000         0.000000  ...      255.000000   \n",
       "75%         1.000000         0.000000  ...      255.000000   \n",
       "max         1.000000      7479.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       125973.000000           125973.000000           125973.000000   \n",
       "mean           115.653005                0.521242                0.082951   \n",
       "std            110.702741                0.448949                0.188922   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             63.000000                0.510000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                125973.000000                125973.000000   \n",
       "mean                      0.148379                     0.032542   \n",
       "std                       0.308997                     0.112564   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         125973.000000             125973.000000         125973.000000   \n",
       "mean               0.284452                  0.278485              0.118832   \n",
       "std                0.444784                  0.445669              0.306557   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             125973.000000  \n",
       "mean                   0.120240  \n",
       "std                    0.319459  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'attack_type', 'attack_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_types = defaultdict(list)\n",
    "with open('nsl-kdd/kddcup_names.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        col, coltype = line.replace('.', '').strip().split(': ')\n",
    "        column_types[coltype].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['continuous', 'symbolic'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['duration',\n",
    "              'src_bytes',\n",
    "              'dst_bytes',\n",
    "              'wrong_fragment',\n",
    "              'urgent',\n",
    "              'hot',\n",
    "              'num_failed_logins',\n",
    "              'num_compromised',\n",
    "              'num_root',\n",
    "              'num_file_creations',\n",
    "              'num_shells',\n",
    "              'num_access_files',\n",
    "              'num_outbound_cmds',\n",
    "              'count',\n",
    "              'srv_count',\n",
    "              'serror_rate',\n",
    "              'srv_serror_rate',\n",
    "              'rerror_rate',\n",
    "              'srv_rerror_rate',\n",
    "              'same_srv_rate',\n",
    "              'diff_srv_rate',\n",
    "              'srv_diff_host_rate',\n",
    "              'dst_host_count',\n",
    "              'dst_host_srv_count',\n",
    "              'dst_host_same_srv_rate',\n",
    "              'dst_host_diff_srv_rate',\n",
    "              'dst_host_same_src_port_rate',\n",
    "              'dst_host_srv_diff_host_rate',\n",
    "              'dst_host_serror_rate',\n",
    "              'dst_host_srv_serror_rate',\n",
    "              'dst_host_rerror_rate',\n",
    "              'dst_host_srv_rerror_rate']\n",
    "\n",
    "binary_cols = ['root_shell',\n",
    "                 'su_attempted',\n",
    "                 'land',\n",
    "                 'logged_in',\n",
    "                 'is_host_login',\n",
    "                 'is_guest_login']\n",
    "\n",
    "nominal_cols = ['flag', 'protocol_type', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>land</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.009423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.096612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          root_shell   su_attempted           land      logged_in  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.001342       0.001103       0.000198       0.395736   \n",
       "std         0.036603       0.045154       0.014086       0.489010   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         1.000000       2.000000       1.000000       1.000000   \n",
       "\n",
       "       is_host_login  is_guest_login  \n",
       "count  125973.000000   125973.000000  \n",
       "mean        0.000008        0.009423  \n",
       "std         0.002817        0.096612  \n",
       "min         0.000000        0.000000  \n",
       "25%         0.000000        0.000000  \n",
       "50%         0.000000        0.000000  \n",
       "75%         0.000000        0.000000  \n",
       "max         1.000000        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[binary_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>0.302192</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>...</td>\n",
       "      <td>182.148945</td>\n",
       "      <td>115.653005</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.148379</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.278485</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>0.120240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>24.399618</td>\n",
       "      <td>0.483935</td>\n",
       "      <td>...</td>\n",
       "      <td>99.206213</td>\n",
       "      <td>110.702741</td>\n",
       "      <td>0.448949</td>\n",
       "      <td>0.188922</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.444784</td>\n",
       "      <td>0.445669</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.319459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>7468.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes  wrong_fragment  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05   125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04        0.022687   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06        0.253530   \n",
       "min         0.00000  0.000000e+00  0.000000e+00        0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00        0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00        0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02        0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09        3.000000   \n",
       "\n",
       "              urgent            hot  num_failed_logins  num_compromised  \\\n",
       "count  125973.000000  125973.000000      125973.000000    125973.000000   \n",
       "mean        0.000111       0.204409           0.001222         0.279250   \n",
       "std         0.014366       2.149968           0.045239        23.942042   \n",
       "min         0.000000       0.000000           0.000000         0.000000   \n",
       "25%         0.000000       0.000000           0.000000         0.000000   \n",
       "50%         0.000000       0.000000           0.000000         0.000000   \n",
       "75%         0.000000       0.000000           0.000000         0.000000   \n",
       "max         3.000000      77.000000           5.000000      7479.000000   \n",
       "\n",
       "            num_root  num_file_creations  ...  dst_host_count  \\\n",
       "count  125973.000000       125973.000000  ...   125973.000000   \n",
       "mean        0.302192            0.012669  ...      182.148945   \n",
       "std        24.399618            0.483935  ...       99.206213   \n",
       "min         0.000000            0.000000  ...        0.000000   \n",
       "25%         0.000000            0.000000  ...       82.000000   \n",
       "50%         0.000000            0.000000  ...      255.000000   \n",
       "75%         0.000000            0.000000  ...      255.000000   \n",
       "max      7468.000000           43.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       125973.000000           125973.000000           125973.000000   \n",
       "mean           115.653005                0.521242                0.082951   \n",
       "std            110.702741                0.448949                0.188922   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             63.000000                0.510000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                125973.000000                125973.000000   \n",
       "mean                      0.148379                     0.032542   \n",
       "std                       0.308997                     0.112564   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         125973.000000             125973.000000         125973.000000   \n",
       "mean               0.284452                  0.278485              0.118832   \n",
       "std                0.444784                  0.445669              0.306557   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             125973.000000  \n",
       "mean                   0.120240  \n",
       "std                    0.319459  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[continuous_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125973\n",
       "Name: num_outbound_cmds, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['num_outbound_cmds'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'num_outbound_cmds' only has 1 value, so we are dropping from our dataframes and continuous columns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = 'num_outbound_cmds')\n",
    "df_test = df_test.drop(columns = 'num_outbound_cmds')\n",
    "continuous_cols.remove('num_outbound_cmds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125893\n",
       "2        59\n",
       "1        21\n",
       "Name: su_attempted, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['su_attempted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, 'su_attempted' is supposed to be a binary attribute; therefore, we are dropping the \"2\" values and replacing them with the default value of \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['su_attempted'] = df_train['su_attempted'].replace(2,0)\n",
    "df_test['su_attempted'] = df_test['su_attempted'].replace(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125952\n",
       "1        21\n",
       "Name: su_attempted, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['su_attempted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for categorical variables and define our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train.drop(columns = ['attack_category','attack_type']), df_test.drop(columns = ['attack_category','attack_type'])])\n",
    "df_total = pd.get_dummies(df_total, columns = nominal_cols, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['attack_category']\n",
    "y_test = df_test['attack_category']\n",
    "\n",
    "X = df_total[:len(df_train)]\n",
    "X_test = df_total[-len(df_test):]\n",
    "\n",
    "col_names = list(df_total.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['attack_category'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, despite malicious vs benign label distributions being fairly even, there is a very uneven distribution of the types of attacks in our training data. In order to increase the representation of some of the minority classes and decrease the representation of some of the majority classes, we take a resampling approach that combines oversampling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2l       67343\n",
      "u2r       67343\n",
      "benign    67343\n",
      "dos       67343\n",
      "probe     67343\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(sampling_strategy='auto', random_state=1)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "print(pd.Series(y_sm).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign    25194\n",
      "u2r       25194\n",
      "probe     25194\n",
      "r2l       25194\n",
      "dos       25194\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mean_len = int(pd.Series(y).value_counts().sum()/5)\n",
    "ratio = {'benign': mean_len,\n",
    "         'dos': mean_len,\n",
    "         'probe': mean_len,\n",
    "         'r2l': mean_len,\n",
    "         'u2r': mean_len}\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=ratio, random_state=1, replacement=True)\n",
    "X_rus, y_rus = rus.fit_resample(X_sm, y_sm)\n",
    "print(pd.Series(y_rus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_rus).value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-valudate 6 potential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'rf_model': RandomForestClassifier(random_state=2), \\\n",
    "          'lr_model': LogisticRegression(solver = 'newton-cg', random_state = 3), \\\n",
    "         'dt_model': DecisionTreeClassifier(random_state = 2), \\\n",
    "         'xgb_model': XGBClassifier(random_state = 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('scaler', StandardScaler(), continuous_cols)\n",
    "], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_accuracy(X, y, model):\n",
    "    model_pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    return list(cross_val_score(model_pipeline, X, y, cv = 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_model\n",
      "lr_model\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for model in models:\n",
    "    print(model)\n",
    "    accuracies = get_cv_accuracy(X_rus, y_rus, models[model])\n",
    "    for acc in accuracies:\n",
    "        scores.append((model, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(scores, columns = ['Model', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Model', y = 'Accuracy', data = df_models).set_title('3-Fold Cross-Validation')\n",
    "sns.stripplot(x = 'Model', y = 'Accuracy', data = df_models, size = 8, jitter = True, edgecolor = 'gray', linewidth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_multi_v1 = Pipeline([('preprocessor', preprocessor), ('model', models['xgb_model'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_multi_v1.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_preds = xgb_multi_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, multi_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_preds = [0.0 if x == 'benign' else 1.0 for x in multi_preds]\n",
    "simple_y = y_test.map(lambda x: 0.0 if x == 'benign' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(simple_y, simple_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-class classification of attack type does a decent job at identifying attack types; however, its recall for identifying malicious traffic is too low. I decided to focus more on intrusion detection than attack classification, but still valued the results above in choosing an algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rus_benign = y_rus.map(lambda x: 0.0 if x == 'benign' else 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'rf_model': RandomForestClassifier(random_state=2), \\\n",
    "          'lr_model': LogisticRegression(random_state = 2), \\\n",
    "         'dt_model': DecisionTreeClassifier(random_state = 2), \\\n",
    "         'xgb_model': XGBClassifier(random_state = 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('scaler', StandardScaler(), continuous_cols)\n",
    "], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_accuracy(X, y, model):\n",
    "    model_pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    return list(cross_val_score(model_pipeline, X, y, cv = 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I decided to reduce the number of features through SelectPercentile, performing ANOVA tests and returning the F-values for the features to determine their independent relevance to the target vector. After some experimentation, I decided to keep the top 33% of features according to their F-score. I chose to measure the Area Under the Curve (AUC) for the ROC curve so I could later optimize the threshold to reduce false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_roc(X, y, model):\n",
    "    model_pipeline = Pipeline([('preprocessor', preprocessor), ('select', SelectPercentile(percentile = 33)), ('model', model)])\n",
    "    return list(cross_val_score(model_pipeline, X, y, cv = 5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_scores = []\n",
    "for model in models:\n",
    "    print(model)\n",
    "    aucs = get_cv_roc(X_rus, y_rus_benign, models[model])\n",
    "    for auc in aucs:\n",
    "        roc_scores.append((model, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(roc_scores, columns = ['Model', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Model', y = 'AUC', data = df_models).set_title('AUC')\n",
    "sns.stripplot(x = 'Model', y = 'AUC', data = df_models, size = 8, jitter = True, edgecolor = 'gray', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble forest methods tended to perform better according to the AUC measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_models = {'rf_model': RandomForestClassifier(random_state=2), \\\n",
    "         'xgb_model': XGBClassifier(random_state = 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model in forest_models:\n",
    "    print(model)\n",
    "    accuracies = get_cv_roc(X_rus, y_rus_benign, forest_models[model])\n",
    "    for acc in accuracies:\n",
    "        scores.append((model, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forests = df_models[(df_models['Model'] == 'rf_model') | (df_models['Model'] == 'xgb_model')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Model', y = 'AUC', data = df_forests).set_title('5-Fold Cross-Validation')\n",
    "sns.stripplot(x = 'Model', y = 'AUC', data = df_forests, size = 8, jitter = True, edgecolor = 'gray', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I chose the XGB model because it outperformed the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = Pipeline(\n",
    "    [('preprocessor', preprocessor), \n",
    "     ('select', SelectPercentile(percentile = 33)),\n",
    "     ('model', models['xgb_model'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline2 = Pipeline([('preprocessor', preprocessor), ('select', SelectPercentile(percentile = 33)), ('model', models['xgb_model'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Threshold Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_rus, y_rus, test_size = .2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_benign = y_train.map(lambda x: 0.0 if x == 'benign' else 1.0)\n",
    "y_val_benign = y_val.map(lambda x: 0.0 if x == 'benign' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_benign = y_test.map(lambda x: 0.0 if x == 'benign' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline.fit(X_train, y_train_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xgb_pipeline.steps[2][1].feature_importances_), 'total features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal threshold\n",
    "#### I plot the ROC curve and determine the threshold where the true positive rate is 1 (TP/TP+FP). The goal is to maximize recall and minimize the number of attacks that pass through the detection system while not sacrificing the integrity of the algorithm by flagging too many false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_probabilities = xgb_pipeline.predict_proba(X_val)[:,1]\n",
    "false_positive_rate, true_positive_rate, threshold = metrics.roc_curve(y_val_benign, target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0.0, 1.0], ls=\"--\")\n",
    "plt.plot([0.0, 0.0], [1.0, 0.0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0.0, 1.0], ls=\"--\")\n",
    "plt.plot([0.0, 0.0], [1.0, 0.0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.axis([0.0, 0.001, 0.95, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = 0\n",
    "for i in range(len(threshold)):\n",
    "    if true_positive_rate[i] == 1.0:\n",
    "        optimal_threshold = threshold[i]\n",
    "        print(optimal_threshold)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds_new = [1.0 if x >= optimal_threshold else 0.0 for x in target_probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_val_benign, y_val_preds_new))\n",
    "print(classification_report(y_val_benign, y_val_preds_new))\n",
    "print(confusion_matrix(y_val_benign, y_val_preds_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With this set threshold, the recall in the validation set is maximized, keeping the number of false negatives (ie attacks that weren't detected) to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = xgb_pipeline.predict_proba(X_test)[:,1]\n",
    "y_test_preds_new = [1.0 if x >= optimal_threshold else 0.0 for x in test_probabilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation post-threshold shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Classification Report\")\n",
    "y_preds_base = ([0]*9625) + ([1]*3208) + ([0]*261) + ([1]*9450)\n",
    "y_test_base = ([0]*9625) + ([0]*3208) + ([1]*261) + ([1]*9450)\n",
    "print(accuracy_score(y_test_base, y_preds_base))\n",
    "print(classification_report(y_test_base, y_preds_base))\n",
    "print(confusion_matrix(y_test_base, y_preds_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test_benign, y_test_preds_new))\n",
    "print(classification_report(y_test_benign, y_test_preds_new))\n",
    "print(confusion_matrix(y_test_benign, y_test_preds_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = 1209\n",
    "false_neg = 1093\n",
    "num_samples = 22544\n",
    "print('True positive %: {}'.format(1-(false_pos/num_samples)))\n",
    "print('True negative %: {}'.format(1-(false_neg/num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = xgb_pipeline.predict_proba(X_test)[:,1]\n",
    "y_test_preds_new = [1.0 if x >= optimal_threshold else 0.0 for x in test_probabilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My approach has an improved accuracy score 5.2% higher than the baseline and an improved true positive percentage by 8.9% , with the sacrifice of a decreased true negative percentage by 3.7%. With a precision of 91%, if my algorithm flags an attack, there is a 91% chance it is an actual attack, as opposed to the 75% chance that an attack flagged by the baseline is an actual attack. \n",
    "\n",
    "#### With my model, there are 832 more unflagged attacks, but 1999 fewer cases that were labeled as an attack but weren't. A topic that may spawn further research from my end is measuring the impact of attacks vs impact of the security team focusing on false positives. Just speculating, one may expect an undetected attack to have a much greater adverse impact than a false positive, but if a security analyst is spending all their time mitigating false positives, they may be too late to mitigate an actual attack. For the sake of not vearing too far off topic, let's just assume that a false negative is 2x as bad as a false positive to an organization. So the loss of 1999 false positives outweighs the gain of 832 false negatives. (1999 - (832*2) = 335).\n",
    "\n",
    "#### I wanted to further explore ways I could improve the recall while maintaining the precision I had. Thinking about cyber attack patterns, many attackers will create new malware that is either slightly different from a previous version, very different, or a completely new zero day exploit. So how can a machine learning algorithm label an instance that is slightly/very different or even not at all similar to any of the training data its seen? Clustering can help with all of the above, to group similar occurances as well as detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Unsupervised Modeling - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_val_, y_train_orig, y_val_orig = train_test_split(X, y, test_size = .2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train_[continuous_cols]\n",
    "X_train_ = preprocessor.fit_transform(X_train_)\n",
    "X_val_ = X_val_[continuous_cols]\n",
    "X_val_ = preprocessor.transform(X_val_)\n",
    "X_test_ = X_test[continuous_cols]\n",
    "X_test_ = preprocessor.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = y_train_orig.map(lambda x: 0.0 if x == 'benign' else 1.0)\n",
    "y_val_ = y_val_orig.map(lambda x: 0.0 if x == 'benign' else 1.0)\n",
    "y_test_ = y_test.map(lambda x: 0.0 if x == 'benign' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Actual\n",
    "# Use PCA to reduce dimensionality so we can visualize the dataset on a 2d plot\n",
    "pca = PCA(n_components=2)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "colors = ['red', 'green']\n",
    "\n",
    "for color, cat in zip(colors, [1.0, 0.0]):\n",
    "    if cat == 1.0:\n",
    "        lab = 'malicious'\n",
    "    else:\n",
    "        lab = 'benign'\n",
    "    plt.scatter(train_x_pca_cont[y_train_==cat, 0], train_x_pca_cont[y_train_==cat, 1],\n",
    "                color=color, alpha=.8, lw=2, label=lab)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('Actual', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted\n",
    "# Fit the training data to a k-means clustering estimator model\n",
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=2).fit(X_train_)\n",
    "\n",
    "# Retrieve the labels assigned to each training sample\n",
    "kmeans_y = kmeans.labels_\n",
    "\n",
    "# Plot in 2d with train_x_pca_cont\n",
    "plt.figure(figsize=(15,10))\n",
    "colors = ['red', 'green']\n",
    "\n",
    "for color, cat in zip(colors[:num_clusters], range(num_clusters)):\n",
    "    plt.scatter(train_x_pca_cont[kmeans_y==cat, 0],\n",
    "                train_x_pca_cont[kmeans_y==cat, 1],\n",
    "                color=color, alpha=.8, lw=2, label=cat)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, using 2 clusters for benign and malicious doesn't work very well. So I experimented with different sizes and techniques for determining whether each cluster should be labeled malicious or benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The techniques used to label malicious or benign include outlier detection (unseen attacks in the training set may look like outliers in the holdout set) and cases where the significant majority of the cluster is labeled as malicious. These techniques focus on maximizing malicous recall since that's how I'm aiming to suppliment the xgboost model.\n",
    "\n",
    "#### To sum it up:\n",
    "- If the % of malicious traffic within a cluster is greater than 95%, all instances in the cluster are labeled as malicious.\n",
    "- If the cluster size relative to the total population is less than 0.1%, all instances in the cluster are labeled as malicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mal_k(num_clusters, X_train, percentage = .95, proportion = .001):\n",
    "    '''\n",
    "    Returns malicious cluster numbers as well as a dataframe for labeling each cluster\n",
    "    num_clusters: number of clusters to perform k-means on\n",
    "    X_train: Training data\n",
    "    percentage: Percentage of which malicious labels must be above for the cluster to be labeled malicious.\n",
    "    proportion: The size of the cluster\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2)\n",
    "    kmeans.fit(X_train)\n",
    "    kmeans_train_y = kmeans.labels_\n",
    "    df_crosstab = pd.crosstab(kmeans_train_y, y_train_, rownames = ['cluster'])\n",
    "    df_crosstab['mal_perc'] = df_crosstab[1.0] / (df_crosstab[1.0] + df_crosstab[0.0])\n",
    "    df_crosstab['outlier'] = (df_crosstab[1.0] + df_crosstab[0.0]) <= (len(X_train) * proportion)\n",
    "    df_crosstab2 = df_crosstab.copy()\n",
    "    def label_mal(df):\n",
    "        if (df['mal_perc'] >= .95) or (df['outlier'] == True):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    df_crosstab2['label_malicious'] = df_crosstab2.apply(label_mal, axis = 1)\n",
    "    df_crosstab = df_crosstab[(df_crosstab['mal_perc'] >= percentage) | (df_crosstab['outlier'] == True)]\n",
    "    return list(df_crosstab.index), df_crosstab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize parameters\n",
    "- After optimizing for the F1 Score to balance precision and recall, the parameters chosen were a cluster size of 27, malicious label percentage of 95%, and cluster sample proportion of 0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=31)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_ks, df_crosstab = get_mal_k(27, train_x_pca_cont, .95, .001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosstab.rename(columns = {0.0: 'benign', 1.0: 'malicious'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "n = 27\n",
    "for i in range(n):\n",
    "    if i in mal_ks:\n",
    "        colors.append('red')\n",
    "    else:\n",
    "        colors.append('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit the training data to a k-means clustering estimator model\n",
    "num_clusters = 27\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=2).fit(train_x_pca_cont)\n",
    "\n",
    "# Retrieve the labels assigned to each training sample\n",
    "kmeans_y = kmeans.labels_\n",
    "\n",
    "# Plot in 2d with train_x_pca_cont\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)\n",
    "for color, cat in zip(colors[:num_clusters], range(num_clusters)):\n",
    "    plt.scatter(train_x_pca_cont[kmeans_y==cat, 0],\n",
    "                train_x_pca_cont[kmeans_y==cat, 1],\n",
    "                color=color, alpha=.8, lw=2, label=cat)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('Predicted', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensionality so we can visualize the dataset on a 2d plot\n",
    "pca = PCA(n_components=2)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "colors = ['red', 'green']\n",
    "\n",
    "for color, cat in zip(colors, [1.0, 0.0]):\n",
    "    plt.scatter(train_x_pca_cont[y_train_==cat, 0], train_x_pca_cont[y_train_==cat, 1],\n",
    "                color=color, alpha=.8, lw=2, label=cat)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('Actual', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combine Supervised and Unsupervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=31)\n",
    "train_x_pca_cont = pca.fit_transform(X_train_)\n",
    "test_x_pca_cont = pca.transform(X_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=27, random_state=2)\n",
    "kmeans.fit(train_x_pca_cont)\n",
    "mal_ks = get_mal_k(27, train_x_pca_cont, .95, .001)[0]\n",
    "\n",
    "kmeans_train_labels = kmeans.labels_\n",
    "kmeans_test_labels = kmeans.predict(test_x_pca_cont)\n",
    "kmeans_test_y = [1.0 if y in mal_ks else 0.0 for y in kmeans_test_labels]\n",
    "\n",
    "\n",
    "y_test_preds_combined = [max(kmeans_test_y[i], y_test_preds_new[i]) for i in range(len(kmeans_test_y))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Classification Report\")\n",
    "y_preds_base = ([0]*9625) + ([1]*3208) + ([0]*261) + ([1]*9450)\n",
    "y_test_base = ([0]*9625) + ([0]*3208) + ([1]*261) + ([1]*9450)\n",
    "print(accuracy_score(y_test_base, y_preds_base))\n",
    "print(classification_report(y_test_base, y_preds_base))\n",
    "print(confusion_matrix(y_test_base, y_preds_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = 3208\n",
    "false_neg = 261\n",
    "num_samples = 22544\n",
    "print('True positive %: {}'.format(1-(false_pos/num_samples)))\n",
    "print('True negative %: {}'.format(1-(false_neg/num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Approach\")\n",
    "print(accuracy_score(y_test_benign, y_test_preds_new))\n",
    "print(classification_report(y_test_benign, y_test_preds_new))\n",
    "print(confusion_matrix(y_test_benign, y_test_preds_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = 1209\n",
    "false_neg = 1093\n",
    "num_samples = 22544\n",
    "print('True positive %: {}'.format(1-(false_pos/num_samples)))\n",
    "print('True negative %: {}'.format(1-(false_neg/num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification & Clustering Combined Approach')\n",
    "print(accuracy_score(y_test_benign, y_test_preds_combined))\n",
    "print(classification_report(y_test_benign, y_test_preds_combined))\n",
    "print(confusion_matrix(y_test_benign, y_test_preds_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = 1214\n",
    "false_neg = 984\n",
    "num_samples = 22544\n",
    "print('True positive %: {}'.format(1-(false_pos/num_samples)))\n",
    "print('True negative %: {}'.format(1-(false_neg/num_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complementing classification with clustering went as planned, where it improved the recall for malicious traffic while maintaining precision.  In combining classification with clustering, the algorithm found 109 new malicious attacks at the small price of only mislabeling 5; thereby, increased classifier performance without degrading its integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline.fit(X_train, y_train_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_new = xgb_pipeline.steps[0][1].transform(X_train)\n",
    "X_train_new = xgb_pipeline.steps[1][1].transform(X_train_new)\n",
    "\n",
    "X_test_new = xgb_pipeline.steps[0][1].transform(X_test)\n",
    "X_test_new = xgb_pipeline.steps[1][1].transform(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new2 = xgb_pipeline2.steps[0][1].transform(X_train)\n",
    "X_train_new2 = xgb_pipeline2.steps[1][1].transform(X_train_new2)\n",
    "X_test_new2 = xgb_pipeline2.steps[0][1].transform(X_test)\n",
    "X_test_new2 = xgb_pipeline2.steps[1][1].transform(X_test_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mal(df):\n",
    "    if (df['mal_perc'] >= .95) or (df['outlier'] == True):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "df_crosstab = pd.crosstab(kmeans_train_labels, y_train_)\n",
    "\n",
    "df_crosstab['mal_perc'] = df_crosstab[1.0] / (df_crosstab[1.0] + df_crosstab[0.0])\n",
    "outliers = (df_crosstab[1.0] + df_crosstab[0.0]) <= (len(X_train_) * .001)\n",
    "df_crosstab['outlier'] = outliers\n",
    "malicious_labels = df_crosstab.apply(label_mal, axis = 1)\n",
    "df_crosstab['label_malicious'] = malicious_labels\n",
    "df_crosstab = pd.crosstab(kmeans_train_labels, y_train_orig)\n",
    "df_crosstab['label_malicious'] = malicious_labels\n",
    "df_crosstab['outlier'] = outliers\n",
    "df_crosstab['max'] = df_crosstab.iloc[:,:4].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_instance(i, df_crosstab):\n",
    "    mal_dict = {0.0: 'benign', 1.0: 'malicious'}\n",
    "    def label_mal(df):\n",
    "        if (df['mal_perc'] >= .95) or (df['outlier'] == True):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    if kmeans_test_y[i] > y_test_preds_new[i]:\n",
    "        print('cluster:', kmeans_test_labels[i])\n",
    "        print('Actual Value:', y_test_benign[i])\n",
    "        print('Predicted value:', y_test_preds_combined[i])\n",
    "        \n",
    "        \n",
    "        df_cluster_weights = pd.DataFrame(columns = continuous_cols, data = kmeans.cluster_centers_)\n",
    "        cg = sns.clustermap(df_cluster_weights, vmin = -3, vmax = 3)\n",
    "        row_order = cg.dendrogram_row.reordered_ind\n",
    "        plot = plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "        cg.ax_heatmap.add_patch(Rectangle((0, row_order.index(kmeans_test_labels[i])), 31, 1, fill=False, edgecolor='yellow', lw=4, clip_on=False))\n",
    "        \n",
    "        cg.ax_heatmap.tick_params(length=0)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        if df_crosstab.loc[kmeans_test_labels[i]]['outlier'] == True:\n",
    "            reason = 'outlier'\n",
    "        else:\n",
    "            reason = df_crosstab.loc[kmeans_test_labels[i]]['max']\n",
    "        \n",
    "        feature_tup = sorted(dict(df_cluster_weights.iloc[kmeans_test_labels[i]]).items(), key = lambda x: abs(x[1]), reverse = True)\n",
    "        names = [x[0] for x in feature_tup][:10]\n",
    "        vals = [X_test.iloc[i][x[0]] for x in feature_tup][:10]\n",
    "        df_features = pd.DataFrame({'Feature': names, 'Original Values': vals})\n",
    "        display(df_features)\n",
    "        print('This sample is labeled as', str(mal_dict[y_test_preds_combined[i]]) + ', part of which may be explained by its', feature_tup[0][0], 'of', X_test.iloc[i][feature_tup[0][0]], ',', feature_tup[1][0], 'of', X_test.iloc[i][feature_tup[1][0]], ',and', feature_tup[2][0], 'of', X_test.iloc[i][feature_tup[2][0]])\n",
    "        print('This attack is most likely classified as', reason + '.')\n",
    "    else:\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train_new ,class_names=[0.0, 1.0], feature_names = list(X_train.columns[xgb_pipeline.steps[1][1].get_support()]),\n",
    "                                                   discretize_continuous = False, mode = 'classification')\n",
    "        exp = explainer.explain_instance(X_test_new[i], xgb_pipeline.steps[2][1].predict_proba, num_features=10)\n",
    "        exp.as_pyplot_figure()\n",
    "        print('Predicted Proba:', xgb_pipeline.steps[2][1].predict_proba(X_test_new[[i]])[:, 1][0])\n",
    "        print('Optimal Threshold:', optimal_threshold)\n",
    "\n",
    "        print('Actual Value:', y_test_benign[i])\n",
    "        print('Predicted value:', y_test_preds_combined[i])\n",
    "        feature_tup = exp.as_list()\n",
    "        names = [x[0] for x in feature_tup]\n",
    "        vals = [X_test.iloc[i][x[0]] for x in feature_tup]\n",
    "        df_features = pd.DataFrame({'Feature': names, 'Original Values': vals})\n",
    "        display(df_features)\n",
    "        \n",
    "        print('This sample is labeled as', str(mal_dict[y_test_preds_combined[i]]) + ', part of which may be explained by its', feature_tup[0][0], 'of', X_test.iloc[i][feature_tup[0][0]], ',', feature_tup[1][0], 'of', X_test.iloc[i][feature_tup[1][0]], ',and', feature_tup[2][0], 'of', X_test.iloc[i][feature_tup[2][0]])\n",
    "        if y_test_preds_combined[i] == 1.0:\n",
    "            if xgb_pipeline2.steps[2][1].predict(X_test_new2[[i]])[0] != 'benign':\n",
    "                print('This attack is most likely classified as', xgb_pipeline2.steps[2][1].predict(X_test_new2[[i]])[0] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_instance(1, df_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explain_instance(87, df_crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out my [Network Intrusion Detection Engine Dashboard](https://shaeferd-network-traffic-prediction-detection-dashboard-wo3p21.streamlitapp.com/) to better understand why the model made certain predictions and the actionable insights that can be learned from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that the XGBoost multi-class predictor, mapped to binary labels, has the highest precision at 97%. Unfortunately, this model underperforms in every other area. Comparing the ensemble model to main baseline of the Chio Freeman model, there is a precision improvement of 16%, signifying improved confidence in Intrusion Detection System's flagged samples. The Chio Freeman model still outperforms the other models in recall at 97%, with my ensemble model following at 92%. I believe there is still room for improvement in this area. The F1 score for the ensemble model outperforms the others, with the thresholded XGBoost model following closely at 0.91. The ensemble model outperformed the Chio Freeman baseline by 0.05. The high F1 score reflects my goal of optimizing precision and recall. The ensemble model and the thresholded XGBoost models are very similar in accuracy, with the rounded accuracy 90% for each. Finally, the ensemble model outperformed the others in weighted cost at 220,000 cheaper than the next best performer and 540,000 less costly than the Chio Freeman model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Next Steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Risk score calculation\n",
    "- Cost metric formulation\n",
    "- Multi-class model refinement\n",
    "- Remediation path alignment\n",
    "- Building a production-ready dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_pipelines\n",
    "pickle.dump(xgb_pipeline, open(\"models/xgb_pipeline.sav\", 'wb'))\n",
    "pickle.dump(xgb_pipeline2, open(\"models/xgb_pipeline2.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "pickle.dump(kmeans, open(\"models/kmeans.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label lists\n",
    "df_labels = pd.DataFrame({'kmeans_test_y': kmeans_test_y, 'y_test_preds_new': y_test_preds_new,\n",
    "                         'y_test_benign': y_test_benign, 'y_test_preds_combined': y_test_preds_combined,\n",
    "                         'test_probabilities': test_probabilities})\n",
    "df_labels.to_csv('data/labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "X_test.to_csv('data/X_test.csv', index = False)\n",
    "X_train.to_csv('data/X_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays\n",
    "def write_array(file_name, content):\n",
    "    np.savetxt(file_name, content, fmt=\"%2.3f\", delimiter=\",\")\n",
    "write_array('data/X_train_new2.txt', X_train_new2)\n",
    "write_array('data/X_test_new2.txt', X_test_new2)\n",
    "write_array('data/X_train_new.txt', X_train_new)\n",
    "write_array('data/X_test_new.txt', X_test_new)\n",
    "# write_array('data/continuous_cols.txt', continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = pd.DataFrame({\"continuous_cols\": continuous_cols})\n",
    "df_cont.to_csv('data/continuous_cols.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels = pd.DataFrame({'y_train_benign': y_train_benign, 'y_train': y_train})\n",
    "df_test_labels.to_csv('data/df_test_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans = pd.DataFrame({'kmeans_test_labels': kmeans_test_labels})\n",
    "df_kmeans.to_csv('data/kmeans_test_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crosstab.to_csv('data/df_crosstab.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
